{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN\n",
    "(paradigm shift)\n",
    "\n",
    "사물(Real World)에 대해 조금이 지워졌다고 가정했을 때\n",
    "이를 복원하여 재생성(Generation)할 수 있다면 인지했다고 말할 수 있습니다.\n",
    "\n",
    "사물을 구성하는 핵심, 골격, 정보 등 Feature를 통해 구성\n",
    "\n",
    "\n",
    "중요성: 입력층과 출력층 사이에 여러 개의 은닉층(hidden layer)들로 이뤄진 인공신경망(Artificial Neural Network, ANN)으로 복잡한 비선형 관계(non-linear relationship)들을 모델링할 수 있습니다.\n",
    "\n",
    "\n",
    "적용: 물체 식별 모델을 위한 심층 신경망 구조에서는 각 물체가 영상의 기본적 요소들의 계층적 구성으로 표현될 수 있습니다. Classification의 목적으로 사용되며 이미지 트레이닝이나 문자 인식과 같은 분야에서 매우 유용하게 사용될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. One-hot Representation\n",
    "\n",
    "[0, 0, 0, 1, 0, 0, ... ]\n",
    "맞는 것에 대해 1, 아닌 것에 대해 0값을 가짐\n",
    "\n",
    "2. Distributed Representation\n",
    "\n",
    "[34.2, 93.2, 45.3, ... ]\n",
    "Number에 대해서 값을 분산시켜서 데이터를 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cognitive Science\n",
    "\n",
    "\n",
    "인간-인간, 인간-동물, 인간-인공물간의 정보처리 활동을 다룸\n",
    "\n",
    "- Artificial Intelligence\n",
    "\n",
    "\n",
    "지능을 다룸\n",
    "\n",
    "- Machine Learning\n",
    "\n",
    "\n",
    "학습능력을 다룸\n",
    "\n",
    "- Deep Learning / Data Mining\n",
    "\n",
    "서로 많은 부분을 공유"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Variable (잠재변수)\n",
    "\n",
    "Deep Neural Learning의 핵심\n",
    "\n",
    "\n",
    "- x\n",
    "\n",
    "\n",
    "실세계에 존재하는 관측 가능한 것: Count 가능 -> 확률로 표현 가능\n",
    "\n",
    "- h (hidden variable)\n",
    "\n",
    "\n",
    "이 세상에 존재하지 않는 가사의 값: 간접적 추측만 가능 -> 수학적으로 모델링 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Latent Variable의 의미영역을 축소시키는 도구\n",
    "\n",
    "\n",
    "1. x와 h를 연관 관계로 묶어주고 x와 연관된 h 탐색 (Network - 구조적 연관성)\n",
    "\n",
    "\n",
    "P(x, h) = P(x|h) * P(h) -> h 의미 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 같이 많이 나타나는 h를 찾을 때 사용되는 x의 개수가 다량으로 분석 (Data - 많은 수의 데이터)\n",
    "\n",
    "\n",
    "데이터 기반 모델링 -> h 의미 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. x - h - y 와 같이 또 다른 변수 y와 연관관계 탐색 (Network - 구조적 연관성)\n",
    "\n",
    "\n",
    "P(x, y, h) -> h 의미 축소"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Single Layer\n",
    "\n",
    "![title](Image/9-1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Multi Layer\n",
    "\n",
    "![title](Image/9-2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation Learning\n",
    "\n",
    "현상과 사물의 특징을 기계가 스스로 파악\n",
    "\n",
    "사물에 대해 학습된 파라미터를 이용하여 숫자 Data로 변환 (Object to Semantic)\n",
    "\n",
    "![title](Image/9-3.png)\n",
    "\n",
    "Image Pixel Data를 인지하여 Class Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 때 여러 차원의 데이터를 저차원으로 표현하기 위해서는 어떻게 해야 할까? (v to 1)\n",
    "\n",
    "[Data]\n",
    "\n",
    "![title](Image/9-4.png)\n",
    "\n",
    "![title](Image/9-5.png)\n",
    "\n",
    "![title](Image/9-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Weighted Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Sum Matrix \n",
      "\n",
      " [[30  2 40]\n",
      " [ 4 90  9]\n",
      " [45  3 30]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = [[10, 2, 8], [2, 15, 3], [5, 1, 5]]\n",
    "data = np.array(data)\n",
    "Weight = [[3, 1, 5], [2, 6, 3], [9, 3, 6]]\n",
    "Weight = np.array(Weight)\n",
    "\n",
    "print('Weighted Sum Matrix \\n\\n', data * Weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Sum: 28.11111111111111\n"
     ]
    }
   ],
   "source": [
    "print('Weighted Sum:', (data * Weight).sum()/9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Average: 6.657894736842105\n"
     ]
    }
   ],
   "source": [
    "print('Weighted Average:', (data * Weight).sum()/Weight.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convolution Neural Network - 추상화 과정의 모습\n",
    "\n",
    "![title](Image/9-7.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convolution Neural Network - 실제 수학적 연산의 모습\n",
    "\n",
    "![title](Image/9-8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v dimension을 가진 데이터를 v' dimension으로 변형시키는 Weight Set을 w라고 하면 \n",
    "\n",
    "W = (v * v')\n",
    "\n",
    "![title](Image/9-9.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "부가정보(context)를 반영하여 구성하는 방법\n",
    "\n",
    "![title](Image/9-10.png)\n",
    "\n",
    "context와 data에 각각에 해당하는 Weight를 적용"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
